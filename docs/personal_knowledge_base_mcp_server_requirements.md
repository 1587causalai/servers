# 需求分析：ME Server

## 1. 引言

本文档旨在阐述一个新的模型上下文协议 (MCP) 服务器的需求，暂定名为"ME Server"。该服务器的主要目标是弥合开发者个人知识体系与其 AI 辅助开发环境（例如 Cursor、集成 AI Copilot 的 VS Code 等）之间的鸿沟。

基于第一性原理思考，该服务器致力于：

*   **服务对象：** 主要服务于拥有该知识库的开发者本人，并有潜力惠及其他希望集成个性化上下文信息的开发者。
*   **解决的问题：** 解决开发者在编码过程中，因手动查阅和回忆个人笔记、项目文档、过往解决方案以及领域特定知识而产生的认知负荷与时间成本。目前的 AI 开发助手往往缺乏对这种个性化的、非公开上下文信息的深度访问能力。

该服务器将使 AI 助手能够"读取"、"理解"并"运用"一组精心组织的个人及项目相关信息，从而提供更精准、个性化且高效的开发者支持。计划集成的核心信息类别包括：

1.  开发者的个人专业简历。
2.  一系列"认知内核"文档（例如：个人见解、方法论、最佳实践等）。
3.  与一组指定的、正在进行的 GitHub 项目相关的信息。

本文档将深入探讨构建此服务器所需的具体功能、数据源、交互模型以及技术考量。

## 2. 核心功能：AI 助手访问个人信息的策略探讨

ME Server 的核心价值在于让 AI 助手能够深度理解开发者，并基于这份理解提供量身定制的帮助。关键在于两点：信息的有效整合，以及 AI 助手便捷访问这些信息的途径。假设我们已拥有以最简便文档形式存在的"完美"个人信息，核心问题便是：如何设计 ME Server 的能力，让 AI 助手能最方便地访问它们？

以下探讨几种不同的策略方案：

### 方案一：直接内容获取 (Direct Content Retrieval)

*   **核心思想**：服务器提供直接的、原子化的工具（MCP Tools）来获取每项信息的原始内容或完整列表。AI 想要什么，就直接"拿"什么。
*   **AI 如何访问（示例）**：
    *   获取简历全文: `get_resume_content()`
    *   列出认知文档: `list_cognitive_docs()`
    *   获取特定认知文档内容: `get_cognitive_doc_content(doc_name_or_id)`
    *   列出活跃项目: `list_active_projects()`
    *   获取项目 README: `get_project_readme(project_name_or_id)`
*   **优点**：
    *   实现简单：服务器端逻辑相对直接。
    *   工具清晰：AI 易于理解和调用。
*   **缺点**：
    *   信息过载：一次性返回全部内容可能过多，AI 需自行处理。
    *   AI 负担重：AI 需自行解析内容以提取关键信息。

### 方案二：语义理解与问答 (Semantic Understanding & Q&A)

*   **核心思想**：服务器内置一定的"智能"，能够理解自然语言问题，在知识库中进行语义搜索、信息提取，甚至初步综合，返回更精确的答案片段或总结。
*   **AI 如何访问（示例）**：
    *   查询简历中的特定经验: `query_resume(question="团队协作经验")`
    *   查询认知文档中的观点: `query_cognitive_docs(question="对微服务架构的看法")`
    *   查询项目中的实现细节: `query_project_details(project_name_or_id, question="用户认证如何实现")`
*   **优点**：
    *   交互自然：AI 可用自然语言查询。
    *   信息精准：返回与问题高度相关的信息。
    *   减轻AI负担：服务器承担部分理解和提取工作。
*   **缺点**：
    *   实现复杂：服务器端需集成 NLP、语义搜索等技术，挑战大。
    *   依赖质量：效果高度依赖知识库内容和算法。

### 方案三：结构化数据与元数据提取 (Structured Data & Metadata Extraction)

*   **核心思想**：服务器对原始信息进行预处理或动态提取，以结构化（如 JSON）的元数据或关键信息点形式提供给 AI。
*   **AI 如何访问（示例）**：
    *   获取简历技能点: `get_resume_skills()` 返回技能列表。
    *   列出认知文档及其摘要、关键词: `list_cognitive_docs_with_summary()`
    *   获取项目技术栈和更新时间: `get_project_metadata(project_name_or_id)` 返回含相关信息的 JSON 对象。
    *   列出项目指定目录内容: `get_project_directory_structure(project_name_or_id, path="src")`
*   **优点**：
    *   AI易于消费：结构化数据易于解析和使用。
    *   平衡复杂度与效用：实现难度介于方案一和方案二之间。
*   **缺点**：
    *   预处理/提取逻辑：服务器需定义和实现提取逻辑。
    *   信息损失可能：摘要或元数据可能无法完全代表原始内容。
    *   灵活性受限：若 AI 需求超出预定义结构，可能不够用。

**实践中的考量**：这些方案并非互斥，实际应用中常常是混合使用。例如，可以提供简历的全文获取（方案一），同时提供认知文档的语义问答（方案二），以及项目文件的结构化元数据（方案三）。选择何种方案或组合，取决于具体场景的需求、预期的 AI 交互深度以及开发资源。

## 3. 初期范围与核心工具 (MVP)

为了快速验证 ME Server 的核心价值并迭代优化，初期的开发将聚焦于一个最简可行产品 (MVP)。该 MVP 的核心目标是让 AI 助手能够访问开发者预先定义好的、关键的个人上下文信息。

### 3.1 核心信息载体

在 MVP 阶段，ME Server 将主要维护和提供以下三个核心的 Markdown 文档。这些文档将存放于用户在服务器启动时通过命令行参数指定的本地目录中，确保了数据的本地化、隐私性和用户对存储位置的完全掌控：

1.  **个人简历 (`resume.md`)**: 包含开发者的专业背景、技能、项目经验等。
2.  **认知内核 (`cognitive_core.md`)**: 记录开发者的核心思考、方法论、经验总结、常用解决方案等。
3.  **GitHub 项目概览 (`projects_overview.md`)**: 描述开发者当前关注的重点 GitHub 项目，可能包括项目简介、目标、当前状态、关键技术点、个人在项目中的角色和贡献，甚至是一些常用的操作指令或思考备忘。

这些文档将由开发者本人直接维护，确保信息的准确性和时效性。ME Server 的职责是可靠地将这些文档内容提供给 AI 助手。

### 3.2 核心 MCP 工具

基于上述核心信息载体，ME Server 在 MVP 阶段将提供以下基础的 MCP 工具，遵循"直接内容获取"策略：

*   **`get_resume_document()`**: 
    *   **描述**: 获取"个人简历" Markdown 文档的全部内容。
    *   **输入**: 无。
    *   **输出**: 包含简历 Markdown 内容的字符串。

*   **`get_cognitive_core_document()`**: 
    *   **描述**: 获取"认知内核" Markdown 文档的全部内容。
    *   **输入**: 无。
    *   **输出**: 包含认知内核 Markdown 内容的字符串。

*   **`get_projects_overview_document()`**: 
    *   **描述**: 获取"GitHub 项目概览" Markdown 文档的全部内容。
    *   **输入**: 无。
    *   **输出**: 包含 GitHub 项目概览 Markdown 内容的字符串。

### 3.3 关于与其他 Server 的协同

ME Server 本身不负责直接执行如 GitHub API 调用等操作。它提供的 `projects_overview.md` 文档可以包含关于如何与其他服务（如专门的 GitHub Server）交互的"元信息"或"背景知识"。AI 助手作为总调度者，可以结合从 ME Server 获取的上下文信息，去调用其他更专业的服务器来完成具体任务。

## 4. 数据源与配置

ME Server 的核心数据源是开发者本人维护的三个 Markdown 文档。为了确保数据的隐私性和用户对存储位置的控制权，并借鉴了 `@1587causalai/configurable-personal-fs-server` 的成功实践，ME Server 将采用以下配置方式：

*   **本地目录指定**：服务器在启动时，必须通过命令行参数接收一个用户指定的本地目录的绝对路径。例如：`npx me-server /path/to/my/personal_data_directory`。
*   **约定文件名**：在该用户指定的目录下，ME Server 会预期找到以下三个具有约定名称的 Markdown 文件：
    *   `resume.md`
    *   `cognitive_core.md`
    *   `projects_overview.md`
*   **服务器职责**：ME Server 的核心职责是安全、可靠地读取并提供这些位于指定目录下的特定文件的内容。服务器本身不存储任何用户数据，也不依赖任何云端存储（在MVP阶段）。

这种方式使得用户可以将其个人敏感信息存放在任何其信任的本地位置，例如加密磁盘、本地版本控制的目录等。

## 5. 技术选型与开发基础

ME Server 的 MVP 版本将基于 `/Users/gongqian/DailyLog/projects/servers/src/me` 目录下的现有代码进行开发。该代码源自 `@1587causalai/configurable-personal-fs-server`，已经包含了 MCP 服务器的基础框架、工具注册机制以及通过命令行参数配置服务目录等核心功能，非常适合作为 ME Server MVP 的起点。开发语言为 TypeScript/Node.js。

## 6. 未来展望

在完成 MVP 并验证核心价值后，ME Server 可以考虑以下潜在的增强方向：

*   **集成云存储同步**：允许用户将其核心 Markdown 文档与云存储服务（如 Google Drive, Dropbox, OneDrive 等）进行同步，实现数据备份和跨设备访问。这需要仔细考虑 OAuth 认证、API 调用、同步逻辑和安全性。
*   **增强的认知内核交互**：引入针对 `cognitive_core.md` 的语义搜索或问答能力（对应我们讨论的策略方案二），使 AI 助手能更智能地从中提取和理解信息。
*   **项目信息动态获取**：探索与本地 Git 仓库或 GitHub API 的更深度集成，以动态获取部分项目信息，而不仅仅依赖于静态的 `projects_overview.md`。
*   **内容更新工具**：提供 MCP 工具允许 AI 助手在用户的授权下，对这三个核心文档进行内容追加或修改（例如，记录一次新的项目复盘到 `cognitive_core.md`）。
*   **更细粒度的访问控制**：（如果未来考虑多用户或更复杂的场景）设计更细致的访问控制机制。 